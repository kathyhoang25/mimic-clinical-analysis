---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 26, 2024 @ 11:59PM (New deadline Feb 5th Extension due to Mac Repairs)
author: "Kathy Hoang, UID: 506333118"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information for reproducibility:
```{r}
#| eval: true
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1. Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email. You'll get GitHub Pro account for free (unlimited public and private repositories).

2. Create a **private** repository `biostat-203b-2024-winter` and add `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `jonathanhori` and `jasenzhang1` for Lec 80) as your collaborators with write permission.

3. Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `main` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `main` branch will be your presentation area. Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in the `main` branch.

4. After each homework due date, course reader and instructor will check out your `main` branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

5. After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

**Answer:** The URL of my Github Repository is <https://github.com/kathyhoang25/biostat-203b-2024-winter.git>

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data v2.2](https://physionet.org/content/mimiciv/2.2/), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. **You must complete Q2 before working on the remaining questions.** (Hint: The CITI training takes a few hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

**Answer:** 
I completed the CITI training. 

Here is the link to my [completion report](https://www.citiprogram.org/verify/?k17f8a122-733a-4782-883f-5306debecc47-60370472).
![Completion Report](../images/completionReport.png)

Here is the link to my [completion certificate](https://www.citiprogram.org/verify/?wc7ad1bdd-3182-464c-a4cb-dea75cb2a104-60370472).
![Completion Certificate](../images/completionCertificate.png)


I obtained the PhysioNet credential for using the MIMIC-IV data:

![PhysioNetCredential.png](../images/PhysioNetCredential.png)


## Q3. Linux Shell Commands

1. Make the MIMIC v2.2 data available at location `~/mimic`. 

**Answer** I created a symbolic link in my home directory called mimic pointing to the MIMIC v2.2 data folder.
```{bash}
#| eval: true
ls -l ~/mimic/
```
Refer to the documentation <https://physionet.org/content/mimiciv/2.2/> for details of data files. Please, do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files and are not big-data-friendly practices. Read from the data folder `~/mimic` directly in following exercises. 

  Use Bash commands to answer following questions.

2. Display the contents in the folders `hosp` and `icu` using Bash command `ls -l`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

```{bash}
ls -l ~/mimic/hosp
```

```{bash}
ls -l ~/mimic/icu
```
**Answer** Gzip is a data compression program and .gz refers to the file format that results from using gzip compression. Thus, the data files are distributed as `.csv.gz` files instead of `.csv` files because they are compressed files. This compression technology reduces the size of the files and allows data to be transferred more quickly.

3. Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

**Answer**

```{bash}
#| eval: false
#man zcat
#man zless
#man zmore
#man zgrep
#note: commented out to avoid long outputs
```

zcat: allows you to view the contents of a compressed (gzipped) file without having to decompress it. It is similar to the cat command, but it works on zipped files, hence the term zcat.

zless: is a command allows you to view the contents of a compressed file one screen at a time without having to decompress it. The biggest difference between the zless command and the zmore command is that zless offers more functionality and is a bit faster since it does not load the entire file into memory before it displays the output (less is more). It is similar to the less command, but it works on zipped files, hence the term zless.

zmore: is a command that allows you to view the contents of a compressed file one screen at a time without having to decompress it. It is similar to the more command, but it works on zipped files, hence the term zmore.

zgrep: is a command that allows you to search compressed files for a regular expression (matching patterns) without having to decompress it. It invokes the grep command, which is short for "global regular expression print", on compressed/gzipped files.

4. (Looping in Bash) What's the output of the following bash script?
```{bash}
#| eval: false
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  ls -l $datafile
done
```
**Answer**The bash script loops through all the files in the `hosp` folder to find files that begin with `a`, `l`, or `pa` and end with `.gz`. The output is the resulting list of three files in the `hosp` folder that met the specified criteria: admissions.csv.gz, labevents.csv.gz, and patients.csv.gz.

Display the number of lines in each data file using a similar loop. (Hint: combine linux commands `zcat <` and `wc -l`.)

**Answer** 
```{bash}
#| eval: true
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  zcat < $datafile | wc -l
done
```

5. Display the first few lines of `admissions.csv.gz`. How many rows are in this data file? How many unique patients (identified by `subject_id`) are in this data file? Do they match the number of patients listed in the `patients.csv.gz` file? (Hint: combine Linux commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

**Answer** 
```{bash}
#| eval: true

#Display the first 5 lines of admissions.csv.gz
for files in ~/mimic/hosp/admissions.csv.gz
do
  zmore < $files | head -n 5
done
```

```{bash}
#| eval: true

#Number of rows in admissions.csv.gz
num_rows=$(zless < ~/mimic/hosp/admissions.csv.gz | wc -l)
echo There are $num_rows rows in admissions.csv.gz.
```


```{bash}
#Unique Patients in admissions.csv.gz
num_uniq_pat=$(zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $1}' | sort | uniq | wc -l)
echo There are $num_uniq_pat unique patients in admissions.csv.gz.

#Scratchwork
#Check that the column selected is subject_id
#zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, '{print $1}' | head
#subject_id is the first column so print $1
#tail -n +2 skips the first row, which is the header/column names so we don't want to include this in our count
## + means line numbering should start from here
#zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | head -n 5
```



```{bash}
#| eval: true
#Unique Patients in patients.csv.gz
num_pat=$(zcat < ~/mimic/hosp/patients.csv.gz | tail -n +2 | awk -F, '{print $1}' | sort | uniq | wc -l) 
echo There are $num_pat unique patients in patients.csv.gz.

#Scratchwork
#Print first few lines of patients.csv.gz using head
#zcat < ~/mimic/hosp/patients.csv.gz | head
#subject_id is the first column so print $1

```

The number of unique patients in the `admissions.csv.gz` file, 180733, does not match the number of patients listed in the `patients.csv.gz` file, 299712. This is because the patients listed in the admissions.csv.gz file represent only the patients who have been admitted to the hospital, while the patients listed in the patients.csv.gz file represent all of the patients in the database.

6. What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `ethnicity`? Also report the count for each unique value of these variables. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, and so on; skip the header line.)

**Answer** Admission Type is of data type: VARCHAR(40) NOT NULL and there are 9 possible values:‘AMBULATORY OBSERVATION’, ‘DIRECT EMER.’, ‘DIRECT OBSERVATION’, ‘ELECTIVE’, ‘EU OBSERVATION’, ‘EW EMER.’, ‘OBSERVATION ADMIT’, ‘SURGICAL SAME DAY ADMISSION’, and ‘URGENT’. These are the counts for each unique value:

```{bash}
#| eval: true
#zless < ~/mimic/hosp/admissions.csv.gz | head -n 5
#column numbers: 6 (admission_type), 8 (admission_location), 10(insurance), 13(race)
#Note: uniq -c counts the number of occurrences of each unique value

#Admission Type
zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $6}' | sort | uniq -c
```
Admission Location is of data type VARCHAR(60) and there are 11 possible values: 'AMBULATORY SURGERY TRANSFER', 'CLINIC REFERRAL', 'EMERGENCY ROOM', 'INFORMATION NOT AVAILABLE', 'INTERNAL TRANSFER TO OR FROM PSYCH', 'PACU', 'PHYSICIAN REFERRAL', 'PROCEDURE SITE', 'TRANSFER FROM HOSPITAL', 'TRANSFER FROM SKILLED NURSING FACILITY', and 'WALK-IN/SELF REFERRAL'. These are the counts for each unique value:

```{bash}
#Admission Location
zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $8}' | sort | uniq -c

```
Insurance is of data type VARCHAR(255) and there are 3 possible values: 'Medicaid', 'Medicare', and 'Other'. These are the counts for each unique value:

```{bash}
#Insurance
zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $10}' | sort | uniq -c
```

Race is of data type VARCHAR(80) and there are 33 possible values. These are the possible values and the counts for each unique value:

```{bash}
#RACE
zless < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | awk -F, '{print $13}' | sort | uniq -c

```

7. _To compress, or not to compress. That's the question._ Let's focus on the big data file `labevents.csv.gz`. Compare compressed gz file size to the uncompressed file size. Compare the run times of `zcat < ~/mimic/labevents.csv.gz | wc -l` versus `wc -l labevents.csv`. Discuss the trade off between storage and speed for big data files. (Hint: `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large `labevents.csv` file after the exercise.)

**Answer**
```{bash}
#Size of gz file
ls -l ~/mimic/hosp/labevents.csv.gz
#1939088924 bytes
ls -lh ~/mimic/hosp/labevents.csv.gz
#1.8 GB

#Size of uncompressed file 
gzip -dk < ~/mimic/hosp/labevents.csv.gz > ~/mimic/hosp/labevents.csv
ls -l ~/mimic/hosp/labevents.csv
#13730083993 bytes
ls -lh ~/mimic/hosp/labevents.csv
#13 GB

#Note: delete after exercise: ~/mimic/hosp/labevents.csv.gz
```

```{bash}
#run time for compressed
time zcat < ~/mimic/hosp/labevents.csv.gz | wc -l

#run time for uncompressed

time wc -l ~/mimic/hosp/labevents.csv
```

The uncompressed files are significantly larger than the compressed files. The uncompressed file `labevents.csv` is 1373008399 3bytes which is about 13 GB, in contrast to the compressed file 'labevents.csv.gz' is only 1939088924 bytes which is about 1.8GB. 

The runtime output shows that 'zcat < ~/mimic/labevents.csv.gz | wc -l' took slightly longer than 'wc -l ~/mimic/labevents.csv'. The difference in run time was more noticeable for user and system time, but real time is relatively the same. 

The tradeoff between storage and speed between these compressed and uncompressed large data files is that compressed files save a lot more storage space but require a longer processing time, but uncompressed files take up an excessive amount of storage but are faster to process. However, this difference in processing time is not that significant for data files of this size. 


## Q4. Who's popular in Price and Prejudice

1. You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder. 
```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```
Explain what `wget -nc` does. Do **not** put this text file `pg42671.txt` in Git. Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.

**Answer** `wget -nc` retrieves files via HTTP or FTP. It allows you to download a file from the internet from the given URL. The `-nc` option stands for "no clobber", and it is used to avoid overwriting existing files. If the file already exists, it will not be downloaded again if you run wget again. 

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
for char in Elizabeth Jane Lydia Darcy
do
  echo $char: $(grep -o -i $char pg42671.txt | wc -l)
done

#NOTES
  #loops through each character name
  #-o prints only matched characters instead of the whole line
  #-i ignores case
  #grep will search for pattern (char) in the file pg42671.txt
  #wc -l counts the number of lines and returns the number of times each of the 4 character is mentioned
```
Source: [Grep Documentation 2.1](https://www.gnu.org/software/grep/manual/grep.html#Command_002dline-Options)

2. What's the difference between the following two commands?
```{bash}
#| eval: false
echo 'hello, world' > test1.txt

#added my own commands to test
echo 'goodbye, world' > test1.txt
cat test1.txt
```

and

```{bash}
#| eval: false
echo 'hello, world' >> test2.txt

#added my own commands to test
echo 'goodbye, world' >> test2.txt
cat test2.txt

```

**Answer** 

One > OVERWRITES:
The first command with only one > will create a new file with the given input, unless the file already exists, then it will overwrite the file with the given input. In this case, it first created a file with "hello, world" the first time it ran. However, when the second line was run, it rewrote "hello, world" with "goodbye, world". 

Two >> APPENDS:
The second command with two >> will create a new file with the given input if it does not exist yet. If the file exists already, it will append the input to the end of the existing file. In the example above, it first created a file with "hello, world" the first time it ran. However, when the second line was run, it appended "goodbye, world" to "hello, world" so that the text file contained "hello, world" and "goodbye, world".

3. Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:
```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```
**Answer** I used the vi text editor. In the terminal, I typed "vi middle.sh" to create and start editing the file, pressed i to enter INSERT mode, and copied the code above. In order to save, I need to be in the COMMAND mode so I pressed ESC to exit the insert mode. Then I typed :wq to save and exit the file (:w saves and :q quits).

Using `chmod` to make the file executable by the owner, and run
```{bash}
#| eval: false
chmod u+x middle.sh
#make file execute to the user/owner

./middle.sh pg42671.txt 20 5
```
Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

**Answer** The initial argument, "$1", is the filename, pg42671.txt. The second argument, "$2", or end_line, represents the number of lines to be extracted from the file. The third argument, "$3", is the number of lines to be extracted from the previous result.

Thus, the first line (head -n "$2" "$1") will extract the lines from the beginning to the end_line (20) of the file given in the first argument (pg42671.txt). The second line of the shell script (tail -n "$3") will then output the last 5 lines from the previous result of 20 lines. This will then return lines 16-20 of the file pg42671.txt. Both head and tail commands are required to extract the middle lines. Head allows you to specify the end (up to the last line you want), and tail will take a subset from the head output and allow you to specify the start (Tail will give you the last lines up to the start line you want).

[Note: unclear what you mean by first line of shell script so I'm including this too just in case] If you are referring to head -n "$2" "$1", it was already explained above. If you are referring to #!/bin/sh, this is called a shebang, and it is used to specify the interpreter that the system should use to execute the script. In this case, it tells the system to use the Bourne shell (sh) to execute the script.

## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2024`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

**Answer** Please refer to the comments in the code below for the interpretation of the results. The comments above correspond to the command below it.
```{bash}
#| eval: false

#shows just this month's calendar
cal

#shows the calendar for the year 2024
cal 2024

#shows the calendar for specified month and year: September 1752
cal 9 1752
#September 1752 is unusual because it is missing dates Sept 3-13. 
#After doing further research, it turns out that the 11 days missing is 
#due to the delayed adoption of the Gregorian calendar by the British Empire 
#of the Gregorian calendar. These days were skipped as a result of
#political and religious resistance to the calendar change 
#proposed by the Catholic Pope known as the "Calendar Riots of 1752".

#Shows the current date and time
date

#Shows the hostname of the machine (my computer) 
#Ex. CLICC-M-4739, my laptop is lent from UCLA's CLICC 
#but normally it would be my name kathyhoang
hostname

#Shows the architecture of the machine Ex.arm64
arch

# Shows detailed system information for the machine, including the kernel 
#version and the timestamp when the kernel was built, machine architecture
#(arm64), and additional details about the kernel such as the 
#root and version information, etc
uname -a

#Shows the current time, how long the system has been running, 
#the number of users currently logged on, and the
#system load averages for the past 1, 5, and 15 minutes
uptime

#Shows the current user and current time
who am i

#Shows the current users logged in and when they logged in
who

#Shows the current users logged in and information about the users' activities
w

#Shows user and group information, including the current user's UID and GID
id

# Last displays previous logins and head limits it to the most recent 10 logins
last | head

#This line creates a combination of words, uses the curly braces and comma to 
#make various permutations. The first set of curly braces contains prefix options, 
#the second set of curly braces contains the middle part of the word, and the 
#third set of curly braces contains the suffix options that will be appended to
#the end. The comma separates the word options within the curly braces.
echo {con,pre}{sent,fer}{s,ed}

#Time measures the amount of time it takes to execute the sleep 5 command in
#seconds. The sleep 5 command is used to pause the script for 5 seconds. 
#Thus, the output is about 5 seconds in real time, the user time is 0.001 seconds, 
#and the system time is 0.002 seconds.
time sleep 5

#Shows the last 10 commands that were executed in the terminal
history | tail
```

## Q6. Book

1. Git clone the repository <https://github.com/christophergandrud/Rep-Res-Book> for the book _Reproducible Research with R and RStudio_ to your local machine. 

2. Open the project by clicking `rep-res-3rd-edition.Rproj` and compile the book by clicking `Build Book` in the `Build` panel of RStudio. (Hint: I was able to build `git_book` and `epub_book` but not `pdf_book`.)

The point of this exercise is (1) to get the book for free and (2) to see an example how a complicated project such as a book can be organized in a reproducible way.

For grading purpose, include a screenshot of Section 4.1.5 of the book here.

**Answer**I was able to build the book. Here is a screenshot of Section 4.1.5 of the book:

![Section4.1.5](../images/bookscreenshot.png)
